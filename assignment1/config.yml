seed: 50

vocab:
    tokenizer: "word-en"
    output_path: "char-en"
    corpus:
        ["data/junglebook.txt",
        "data/kingjamesbible_tokenized.txt"
        ]

    size: 10000
    min_freq: -1

    spm:
        output_path: ""
        model_type: bpe
        model_name: spm

