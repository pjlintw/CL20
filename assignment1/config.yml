seed: 50

data:
    raw_path: datasets/raw/
    processed_path: datasets/processed/


vocab:
    tokenizer: "word-en"
    output_path: "char-en"
    corpus:
        ["data/junglebook.txt",
        "data/kingjamesbible_tokenized.txt",
        "kdosdkos"
        ]

    size: 10000
    min_freq: -1

    spm:
        output_path: ""
        model_type: bpe
        model_name: spm

